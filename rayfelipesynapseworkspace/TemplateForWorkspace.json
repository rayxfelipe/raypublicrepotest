{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"workspaceName": {
			"type": "string",
			"metadata": "Workspace name",
			"defaultValue": "rayfelipesynapseworkspace"
		},
		"DataLake2_DemoRG_accountKey": {
			"type": "secureString",
			"metadata": "Secure string for 'accountKey' of 'DataLake2_DemoRG'"
		},
		"DataLakeGen2Sri_accountKey": {
			"type": "secureString",
			"metadata": "Secure string for 'accountKey' of 'DataLakeGen2Sri'"
		},
		"rayfelipesynapseworkspace-WorkspaceDefaultSqlServer_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'rayfelipesynapseworkspace-WorkspaceDefaultSqlServer'",
			"defaultValue": "Integrated Security=False;Encrypt=True;Connection Timeout=30;Data Source=tcp:rayfelipesynapseworkspace.sql.azuresynapse.net,1433;Initial Catalog=@{linkedService().DBName}"
		},
		"raysynapse5-WorkspaceDefaultSqlServer_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'raysynapse5-WorkspaceDefaultSqlServer'",
			"defaultValue": "Integrated Security=False;Encrypt=True;Connection Timeout=30;Data Source=tcp:raysynapse5.sql.azuresynapse.net,1433;Initial Catalog=@{linkedService().DBName}"
		},
		"LocalSynapse_LinkedService_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'LocalSynapse_LinkedService'",
			"defaultValue": "Integrated Security=False;Encrypt=True;Connection Timeout=30;Data Source=rayfelipesynapseworkspace.sql.azuresynapse.net;Initial Catalog=\"SQL Dedicated 1\""
		},
		"DataLake2_DemoRG_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://datalakaeacctindemorg.dfs.core.windows.net/"
		},
		"DataLakeGen2Sri_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://datalakemxiar8l.dfs.core.windows.net/"
		},
		"rayfelipesynapseworkspace-WorkspaceDefaultStorage_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://rayfelipedlgen2account.dfs.core.windows.net"
		},
		"raysynapse5-WorkspaceDefaultStorage_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://raystore5.dfs.core.windows.net"
		}
	},
	"variables": {
		"workspaceId": "[concat('Microsoft.Synapse/workspaces/', parameters('workspaceName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('workspaceName'), '/CopyPipeline_89p')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Copy_89p",
						"type": "Copy",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [
							{
								"name": "Source",
								"value": "dcc//CannabisTaxCultivationExciseRevenue.csv"
							},
							{
								"name": "Destination",
								"value": "dbo.CannabisTaxCultivationExciseRevenue"
							}
						],
						"typeProperties": {
							"source": {
								"type": "DelimitedTextSource",
								"storeSettings": {
									"type": "AzureBlobFSReadSettings",
									"recursive": true,
									"enablePartitionDiscovery": false
								},
								"formatSettings": {
									"type": "DelimitedTextReadSettings",
									"skipLineCount": 0
								}
							},
							"sink": {
								"type": "SqlPoolSink",
								"writeBehavior": "Insert",
								"tableOption": "autoCreate"
							},
							"enableStaging": false,
							"translator": {
								"type": "TabularTranslator",
								"mappings": [
									{
										"source": {
											"type": "String",
											"ordinal": 1
										},
										"sink": {
											"name": "Column1",
											"type": "String"
										}
									},
									{
										"source": {
											"type": "String",
											"ordinal": 2
										},
										"sink": {
											"name": "Column2",
											"type": "String"
										}
									},
									{
										"source": {
											"type": "String",
											"ordinal": 3
										},
										"sink": {
											"name": "Column3",
											"type": "String"
										}
									},
									{
										"source": {
											"type": "String",
											"ordinal": 4
										},
										"sink": {
											"name": "Column4",
											"type": "String"
										}
									},
									{
										"source": {
											"type": "String",
											"ordinal": 5
										},
										"sink": {
											"name": "Column5",
											"type": "String"
										}
									},
									{
										"source": {
											"type": "String",
											"ordinal": 6
										},
										"sink": {
											"name": "Column6",
											"type": "String"
										}
									},
									{
										"source": {
											"type": "String",
											"ordinal": 7
										},
										"sink": {
											"name": "Column7",
											"type": "String"
										}
									},
									{
										"source": {
											"type": "String",
											"ordinal": 8
										},
										"sink": {
											"name": "Column8",
											"type": "String"
										}
									},
									{
										"source": {
											"type": "String",
											"ordinal": 9
										},
										"sink": {
											"name": "Column9",
											"type": "String"
										}
									},
									{
										"source": {
											"type": "String",
											"ordinal": 10
										},
										"sink": {
											"name": "Column10",
											"type": "String"
										}
									},
									{
										"source": {
											"type": "String",
											"ordinal": 11
										},
										"sink": {
											"name": "Column11",
											"type": "String"
										}
									},
									{
										"source": {
											"type": "String",
											"ordinal": 12
										},
										"sink": {
											"name": "Column12",
											"type": "String"
										}
									},
									{
										"source": {
											"type": "String",
											"ordinal": 13
										},
										"sink": {
											"name": "Column13",
											"type": "String"
										}
									},
									{
										"source": {
											"type": "String",
											"ordinal": 14
										},
										"sink": {
											"name": "Column14",
											"type": "String"
										}
									},
									{
										"source": {
											"type": "String",
											"ordinal": 15
										},
										"sink": {
											"name": "Column15",
											"type": "String"
										}
									},
									{
										"source": {
											"type": "String",
											"ordinal": 16
										},
										"sink": {
											"name": "Column16",
											"type": "String"
										}
									},
									{
										"source": {
											"type": "String",
											"ordinal": 17
										},
										"sink": {
											"name": "Column17",
											"type": "String"
										}
									}
								],
								"typeConversion": true,
								"typeConversionSettings": {
									"allowDataTruncation": true,
									"treatBooleanAsNumber": false
								}
							}
						},
						"inputs": [
							{
								"referenceName": "SourceDataset_89p",
								"type": "DatasetReference",
								"parameters": {}
							}
						],
						"outputs": [
							{
								"referenceName": "DestinationDataset_89p",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/SourceDataset_89p')]",
				"[concat(variables('workspaceId'), '/datasets/DestinationDataset_89p')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/DestinationDataset_89p')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "SqlPoolTable",
				"schema": [],
				"typeProperties": {
					"schema": "dbo",
					"table": "CannabisTaxCultivationExciseRevenue"
				},
				"sqlPool": {
					"referenceName": "SQL Dedicated 1",
					"type": "SqlPoolReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/sqlPools/SQL Dedicated 1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SourceDataset_89p')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "DataLake2_DemoRG",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": "CannabisTaxCultivationExciseRevenue.csv",
						"fileSystem": "dcc"
					},
					"columnDelimiter": ",",
					"rowDelimiter": "\n",
					"escapeChar": "\\",
					"firstRowAsHeader": false,
					"quoteChar": "\""
				},
				"schema": [
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/DataLake2_DemoRG')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/DataLake2_DemoRG')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('DataLake2_DemoRG_properties_typeProperties_url')]",
					"accountKey": {
						"type": "SecureString",
						"value": "[parameters('DataLake2_DemoRG_accountKey')]"
					}
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/DataLakeGen2Sri')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('DataLakeGen2Sri_properties_typeProperties_url')]",
					"accountKey": {
						"type": "SecureString",
						"value": "[parameters('DataLakeGen2Sri_accountKey')]"
					}
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/PBIDCCDemo')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "PowerBIWorkspace",
				"typeProperties": {
					"workspaceID": "8f1a7afa-fdce-4495-970b-8e25e49593e9",
					"tenantID": "72f988bf-86f1-41af-91ab-2d7cd011db47"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/PowerBIWorkspace1')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "PowerBIWorkspace",
				"typeProperties": {
					"workspaceID": "fcf798ad-1b90-48bb-a5a9-75b0b9417ff5",
					"tenantID": "72f988bf-86f1-41af-91ab-2d7cd011db47"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/rayfelipesynapseworkspace-WorkspaceDefaultSqlServer')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"parameters": {
					"DBName": {
						"type": "String"
					}
				},
				"annotations": [],
				"type": "AzureSqlDW",
				"typeProperties": {
					"connectionString": "[parameters('rayfelipesynapseworkspace-WorkspaceDefaultSqlServer_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/rayfelipesynapseworkspace-WorkspaceDefaultStorage')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('rayfelipesynapseworkspace-WorkspaceDefaultStorage_properties_typeProperties_url')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/raysynapse5-WorkspaceDefaultSqlServer')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"parameters": {
					"DBName": {
						"type": "String"
					}
				},
				"annotations": [],
				"type": "AzureSqlDW",
				"typeProperties": {
					"connectionString": "[parameters('raysynapse5-WorkspaceDefaultSqlServer_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/raysynapse5-WorkspaceDefaultStorage')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('raysynapse5-WorkspaceDefaultStorage_properties_typeProperties_url')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Trigger 1')]",
			"type": "Microsoft.Synapse/workspaces/triggers",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"runtimeState": "Stopped",
				"pipelines": [],
				"type": "ScheduleTrigger",
				"typeProperties": {
					"recurrence": {
						"frequency": "Minute",
						"interval": 3,
						"startTime": "2023-01-23T18:03:00Z",
						"timeZone": "UTC"
					}
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AutoResolveIntegrationRuntime')]",
			"type": "Microsoft.Synapse/workspaces/integrationRuntimes",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "Managed",
				"typeProperties": {
					"computeProperties": {
						"location": "AutoResolve",
						"dataFlowProperties": {
							"computeType": "General",
							"coreCount": 8,
							"timeToLive": 0
						}
					}
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/WorkspaceSystemIdentity')]",
			"type": "Microsoft.Synapse/workspaces/credentials",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "ManagedIdentity",
				"typeProperties": {}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/1-CreateNYCTaxiTripSmallinDedicated')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Quickstarts/2. AnalyzeUsingDedicatedSQLPool"
				},
				"content": {
					"query": "IF NOT EXISTS (SELECT * FROM sys.objects O JOIN sys.schemas S ON O.schema_id = S.schema_id WHERE O.NAME = 'NYCTaxiTripSmall' AND O.TYPE = 'U' AND S.NAME = 'dbo')\nCREATE TABLE dbo.NYCTaxiTripSmall\n    (\n     [DateID] float,\n     [MedallionID] float,\n     [HackneyLicenseID] float,\n     [PickupTimeID] float,\n     [DropoffTimeID] float,\n     [PickupGeographyID] float,\n     [DropoffGeographyID] float,\n     [PickupLatitude] float,\n     [PickupLongitude] float,\n     [PickupLatLong] nvarchar(4000),\n     [DropoffLatitude] float,\n     [DropoffLongitude] float,\n     [DropoffLatLong] nvarchar(4000),\n     [PassengerCount] int,\n     [TripDurationSeconds] int,\n     [TripDistanceMiles] float,\n     [PaymentType] nvarchar(4000),\n     [FareAmount] numeric(19,4),\n     [SurchargeAmount] numeric(19,4),\n     [TaxAmount] numeric(19,4),\n     [TipAmount] numeric(19,4),\n     [TollsAmount] numeric(19,4),\n     [TotalAmount] numeric(19,4)\n    )\nWITH\n    (\n    DISTRIBUTION = ROUND_ROBIN,\n     CLUSTERED COLUMNSTORE INDEX\n     -- HEAP\n    )\nGO\n\nCOPY INTO dbo.NYCTaxiTripSmall\n(DateID 1, MedallionID 2, HackneyLicenseID 3, PickupTimeID 4, DropoffTimeID 5,\nPickupGeographyID 6, DropoffGeographyID 7, PickupLatitude 8, PickupLongitude 9, \nPickupLatLong 10, DropoffLatitude 11, DropoffLongitude 12, DropoffLatLong 13, \nPassengerCount 14, TripDurationSeconds 15, TripDistanceMiles 16, PaymentType 17, \nFareAmount 18, SurchargeAmount 19, TaxAmount 20, TipAmount 21, TollsAmount 22, \nTotalAmount 23)\nFROM 'https://rayfelipedlgen2account.dfs.core.windows.net/rayfelipedlgen2filesystem/Quickstarts/NYCTripSmall-Jan2021.parquet'\nWITH\n(\n    FILE_TYPE = 'PARQUET'\n    ,MAXERRORS = 0\n    ,IDENTITY_INSERT = 'OFF'\n)",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "SQL Dedicated 1",
						"poolName": "SQL Dedicated 1"
					},
					"resultLimit": -1
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/1-NYCTaxiDataFromAzureOpen')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Quickstarts/1. AnalyzeUsingServerless"
				},
				"content": {
					"query": "SELECT TOP 100 * FROM\n    OPENROWSET(\n        BULK 'https://azureopendatastorage.blob.core.windows.net/nyctlc/yellow/puYear=*/puMonth=*/*.parquet',\n        FORMAT='PARQUET'\n    ) AS [nyc]",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/2-NYCPassengerCountAnalysis')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Quickstarts/2. AnalyzeUsingDedicatedSQLPool"
				},
				"content": {
					"query": "SELECT passenger_count,\n      SUM(trip_distance) as SumTripDistance,\n      AVG(trip_distance) as AvgTripDistance\n--INTO dbo.PassengerCountStats\nFROM  dbo.NYCTripSmall\nWHERE trip_distance > 0 AND passenger_count > 0\nGROUP BY passenger_count;\nSELECT * FROM dbo.PassengerCountStats\nORDER BY passenger_count;",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "SQL Dedicated 1",
						"poolName": "SQL Dedicated 1"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/2-NYCTaxiTimeSeriesSeasonalityOutlierAnalysis')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Quickstarts/1. AnalyzeUsingServerless"
				},
				"content": {
					"query": "SELECT\n    YEAR(tpepPickupDateTime) AS current_year,\n    COUNT(*) AS rides_per_year\nFROM\n    OPENROWSET(\n        BULK 'https://azureopendatastorage.blob.core.windows.net/nyctlc/yellow/puYear=*/puMonth=*/*.parquet',\n        FORMAT='PARQUET'\n    ) AS [nyc]\nWHERE nyc.filepath(1) >= '2009' AND nyc.filepath(1) <= '2022'\nGROUP BY YEAR(tpepPickupDateTime)\nORDER BY 1 ASC",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/3-NYCTaxiWithPublicHolidays')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Quickstarts/1. AnalyzeUsingServerless"
				},
				"content": {
					"query": "WITH taxi_rides AS (\nSELECT\n    CAST([tpepPickupDateTime] AS DATE) AS [current_day],\n    COUNT(*) as rides_per_day\nFROM\n    OPENROWSET(\n        BULK 'https://azureopendatastorage.blob.core.windows.net/nyctlc/yellow/puYear=*/puMonth=*/*.parquet',\n        FORMAT='PARQUET'\n    ) AS [nyc]\nWHERE nyc.filepath(1) = '2016'\nGROUP BY CAST([tpepPickupDateTime] AS DATE)\n),\npublic_holidays AS (\nSELECT\n    holidayname as holiday,\n    date\nFROM\n    OPENROWSET(\n        BULK 'https://azureopendatastorage.blob.core.windows.net/holidaydatacontainer/Processed/*.parquet',\n        FORMAT='PARQUET'\n    ) AS [holidays]\nWHERE countryorregion = 'United States' AND YEAR(date) = 2016\n),\njoined_data AS (\nSELECT\n    *\nFROM taxi_rides t\nLEFT OUTER JOIN public_holidays p on t.current_day = p.date\n)\n\nSELECT \n    *,\n    holiday_rides = \n    CASE   \n      WHEN holiday is null THEN 0   \n      WHEN holiday is not null THEN rides_per_day\n    END   \nFROM joined_data\nORDER BY current_day ASC",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Create Views Clean')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Healthcare Data Scripts"
				},
				"content": {
					"query": "--CREATE VIEW [dbo].[County_Cardio_Disease] AS\nSELECT [California County] as County, \nSUM(cast([Cardiovascular Disease] as FLOAT)) as [Cardio Disease]\nFROM [dbo].[calenviroscreen]\ngroup by [California County]\n\n--CREATE VIEW [dbo].[County_Covid_Deaths] AS\nSELECT\n[area] as County, cast([cumulative_deaths] as FLOAT) as [Covid Deaths]\n FROM [dbo].[Covid19CasesTest]\n where area_type != 'State' and date = '' \n\nSELECT c.County, c.[Cardio Disease], \nd.[Covid Deaths]\nfrom dbo.County_Cardio_Disease c, dbo.County_Covid_Deaths d\nwhere c.County = d.County\norder by d.[Covid Deaths] desc\n\n\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "SQL Dedicated 1",
						"poolName": "SQL Dedicated 1"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Create Views Complete')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Healthcare Data Scripts"
				},
				"content": {
					"query": "--CREATE VIEW [dbo].[County_Cardio_Disease] AS\nSELECT [California County] as County, \n--, [ZIP]\n--, [Nearby City (to help approximate location only)]\nSUM(cast([Cardiovascular Disease] as FLOAT)) as [Cardio Disease]\n--, [Cardiovascular Disease Pctl]\nFROM [dbo].[calenviroscreen]\n--where [California County] = 'Ventura'\ngroup by [California County]\n--order by [Cardio Disease] desc\n\n--CREATE VIEW [dbo].[County_Covid_Deaths] AS\nSELECT\n--[date]\n[area] as County, cast([cumulative_deaths] as FLOAT) as [Covid Deaths]\n--[cumulative_deaths]\n FROM [dbo].[Covid19CasesTest]\n where area_type != 'State' and date = '' \n --and area = 'Los Angeles' \n\n\nselect c.County, c.[Cardio Disease], \n--cast(d.[Covid Deaths] as numeric)\n--convert(decimal(18,2),[Covid Deaths])\n--d.[Covid Deaths] as numeric\n--isNumeric(d.[Covid Deaths])\nd.[Covid Deaths]\nfrom dbo.County_Cardio_Disease c, dbo.County_Covid_Deaths d\nwhere c.County = d.County\norder by d.[Covid Deaths] desc\n\n\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/CreateCannabisExploreDB')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "DCC"
				},
				"content": {
					"query": "CREATE DATABASE CannabisDataExplorationDB \n                COLLATE Latin1_General_100_BIN2_UTF8",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/CreateExplorationDB')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Quickstarts/1. AnalyzeUsingServerless"
				},
				"content": {
					"query": "CREATE DATABASE DataExplorationDB \n                COLLATE Latin1_General_100_BIN2_UTF8",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/CreateExternalDataSource')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Quickstarts/1. AnalyzeUsingServerless"
				},
				"content": {
					"query": "CREATE EXTERNAL DATA SOURCE rayfelipedlgen2account\nWITH ( LOCATION = 'https://rayfelipedlgen2account.dfs.core.windows.net')\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/CreateNYCTaxiTripSmallinDedicated')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Quickstarts/2. AnalyzeUsingDedicatedSQLPool"
				},
				"content": {
					"query": "IF NOT EXISTS (SELECT * FROM sys.objects O JOIN sys.schemas S ON O.schema_id = S.schema_id WHERE O.NAME = 'NYCTaxiTripSmall' AND O.TYPE = 'U' AND S.NAME = 'dbo')\nCREATE TABLE dbo.NYCTaxiTripSmall\n    (\n     [DateID] float,\n     [MedallionID] float,\n     [HackneyLicenseID] float,\n     [PickupTimeID] float,\n     [DropoffTimeID] float,\n     [PickupGeographyID] float,\n     [DropoffGeographyID] float,\n     [PickupLatitude] float,\n     [PickupLongitude] float,\n     [PickupLatLong] nvarchar(4000),\n     [DropoffLatitude] float,\n     [DropoffLongitude] float,\n     [DropoffLatLong] nvarchar(4000),\n     [PassengerCount] int,\n     [TripDurationSeconds] int,\n     [TripDistanceMiles] float,\n     [PaymentType] nvarchar(4000),\n     [FareAmount] numeric(19,4),\n     [SurchargeAmount] numeric(19,4),\n     [TaxAmount] numeric(19,4),\n     [TipAmount] numeric(19,4),\n     [TollsAmount] numeric(19,4),\n     [TotalAmount] numeric(19,4)\n    )\nWITH\n    (\n    DISTRIBUTION = ROUND_ROBIN,\n     CLUSTERED COLUMNSTORE INDEX\n     -- HEAP\n    )\nGO\n\nCOPY INTO dbo.NYCTaxiTripSmall\n(DateID 1, MedallionID 2, HackneyLicenseID 3, PickupTimeID 4, DropoffTimeID 5,\nPickupGeographyID 6, DropoffGeographyID 7, PickupLatitude 8, PickupLongitude 9, \nPickupLatLong 10, DropoffLatitude 11, DropoffLongitude 12, DropoffLatLong 13, \nPassengerCount 14, TripDurationSeconds 15, TripDistanceMiles 16, PaymentType 17, \nFareAmount 18, SurchargeAmount 19, TaxAmount 20, TipAmount 21, TollsAmount 22, \nTotalAmount 23)\nFROM 'https://rayfelipedlgen2account.dfs.core.windows.net/rayfelipedlgen2filesystem/Quickstarts/NYCTripSmall-Jan2021.parquet'\nWITH\n(\n    FILE_TYPE = 'PARQUET'\n    ,MAXERRORS = 0\n    ,IDENTITY_INSERT = 'OFF'\n)",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "SQL Dedicated 1",
						"poolName": "SQL Dedicated 1"
					},
					"resultLimit": -1
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/DropCannabisAccountSitesByQuarterTable')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "DCC"
				},
				"content": {
					"query": "DROP external TABLE [dbo].[CannabisAccountSitesByQuarterTable]\nGO\n\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "CannabisDataExplorationDB",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/DropNYCTaxiTripSmall')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Quickstarts/2. AnalyzeUsingDedicatedSQLPool"
				},
				"content": {
					"query": "DROP TABLE [dbo].[NYCTaxiTripSmall]\nGO\n\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "SQL Dedicated 1",
						"poolName": "SQL Dedicated 1"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Join Cardio Disease and Deaths')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Healthcare Data Scripts"
				},
				"content": {
					"query": "CREATE VIEW [dbo].[County_Cardio_Disease] AS\nSELECT [California County] as County, \nSUM(cast([Cardiovascular Disease] as FLOAT)) as [Cardio Disease]\nFROM [dbo].[calenviro]\ngroup by [California County]\n\n\nCREATE VIEW [dbo].[County_Covid_Deaths] AS\nSELECT\n[area] as County, cast([cumulative_deaths] as FLOAT) as [Covid Deaths]\n FROM [dbo].[covid_testcases]\n where area_type != 'State' and date IS NULL\n\n\nselect c.County, c.[Cardio Disease], \nd.[Covid Deaths]\nfrom dbo.County_Cardio_Disease c, dbo.County_Covid_Deaths d\nwhere c.County = d.County\norder by d.[Covid Deaths] desc\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/NYCPassengerCountAnalysis')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Quickstarts/2. AnalyzeUsingDedicatedSQLPool"
				},
				"content": {
					"query": "SELECT passenger_count,\n      SUM(trip_distance) as SumTripDistance,\n      AVG(trip_distance) as AvgTripDistance\n--INTO dbo.PassengerCountStats\nFROM  dbo.NYCTripSmall\nWHERE trip_distance > 0 AND passenger_count > 0\nGROUP BY passenger_count;\nSELECT * FROM dbo.PassengerCountStats\nORDER BY passenger_count;",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "SQL Dedicated 1",
						"poolName": "SQL Dedicated 1"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/NYCTaxiDataFromAzureOpen')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Quickstarts/1. AnalyzeUsingServerless"
				},
				"content": {
					"query": "SELECT TOP 100 * FROM\n    OPENROWSET(\n        BULK 'https://azureopendatastorage.blob.core.windows.net/nyctlc/yellow/puYear=*/puMonth=*/*.parquet',\n        FORMAT='PARQUET'\n    ) AS [nyc]",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/NYCTaxiTimeSeriesSeasonalityOutlierAnalysis')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Quickstarts/1. AnalyzeUsingServerless"
				},
				"content": {
					"query": "SELECT\n    YEAR(tpepPickupDateTime) AS current_year,\n    COUNT(*) AS rides_per_year\nFROM\n    OPENROWSET(\n        BULK 'https://azureopendatastorage.blob.core.windows.net/nyctlc/yellow/puYear=*/puMonth=*/*.parquet',\n        FORMAT='PARQUET'\n    ) AS [nyc]\nWHERE nyc.filepath(1) >= '2009' AND nyc.filepath(1) <= '2022'\nGROUP BY YEAR(tpepPickupDateTime)\nORDER BY 1 ASC",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/NYCTaxiTop100')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Quickstarts/1. AnalyzeUsingServerless"
				},
				"content": {
					"query": "SELECT TOP 100 * FROM\n    OPENROWSET(\n        BULK 'https://azureopendatastorage.blob.core.windows.net/nyctlc/yellow/puYear=*/puMonth=*/*.parquet',\n        FORMAT='PARQUET'\n    ) AS [nyc]",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/NYCTaxiWithPublicHolidays')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Quickstarts/1. AnalyzeUsingServerless"
				},
				"content": {
					"query": "WITH taxi_rides AS (\nSELECT\n    CAST([tpepPickupDateTime] AS DATE) AS [current_day],\n    COUNT(*) as rides_per_day\nFROM\n    OPENROWSET(\n        BULK 'https://azureopendatastorage.blob.core.windows.net/nyctlc/yellow/puYear=*/puMonth=*/*.parquet',\n        FORMAT='PARQUET'\n    ) AS [nyc]\nWHERE nyc.filepath(1) = '2016'\nGROUP BY CAST([tpepPickupDateTime] AS DATE)\n),\npublic_holidays AS (\nSELECT\n    holidayname as holiday,\n    date\nFROM\n    OPENROWSET(\n        BULK 'https://azureopendatastorage.blob.core.windows.net/holidaydatacontainer/Processed/*.parquet',\n        FORMAT='PARQUET'\n    ) AS [holidays]\nWHERE countryorregion = 'United States' AND YEAR(date) = 2016\n),\njoined_data AS (\nSELECT\n    *\nFROM taxi_rides t\nLEFT OUTER JOIN public_holidays p on t.current_day = p.date\n)\n\nSELECT \n    *,\n    holiday_rides = \n    CASE   \n      WHEN holiday is null THEN 0   \n      WHEN holiday is not null THEN rides_per_day\n    END   \nFROM joined_data\nORDER BY current_day ASC",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SQL script 1')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "DCC"
				},
				"content": {
					"query": "CREATE DATABASE CannabisDataExplorationDB \n                COLLATE Latin1_General_100_BIN2_UTF8",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SelectTop100FromExternalDS')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Quickstarts/1. AnalyzeUsingServerless"
				},
				"content": {
					"query": "SELECT\n    TOP 100 *\nFROM\n    OPENROWSET(\n            BULK '/rayfelipedlgen2filesystem/Quickstarts/NYCTripSmall.parquet',\n            DATA_SOURCE = 'rayfelipedlgen2account',\n            FORMAT='PARQUET'\n    ) AS [result]\n\n\n           ",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "DataExplorationDB",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/UpdatePaymentType_sp')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Healthcare Data Scripts"
				},
				"content": {
					"query": "CREATE PROC [dbo].[UpdatePaymentType]\nAS\nBEGIN\nUPDATE [dbo].[greentaxi]\nSET PaymentType = 2\nEND",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/update_covid_gender_unknown_sp')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Healthcare Data Scripts"
				},
				"content": {
					"query": "CREATE PROC [dbo].[update_covid_gender_unknown_sp]\nAS\nBEGIN\nUPDATE [dbo].[bscc_covid_bygender]\nSET demographic_value = 'Unknown'\nWHERE demographic_value = 'Total'\nEND",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "SQL Dedicated 1",
						"poolName": "SQL Dedicated 1"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/1-AnalyzeNYCTaxiDataWithSparkPool')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Quickstarts/4. AnalyzeUsingSparkPool"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "SynapseDemoSprk",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "b44fd067-60e5-4bc4-a08f-5438a21f769b"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/499bc654-f84c-46c2-952c-b30be508f78c/resourceGroups/Synapse-Demo/providers/Microsoft.Synapse/workspaces/rayfelipesynapseworkspace/bigDataPools/SynapseDemoSprk",
						"name": "SynapseDemoSprk",
						"type": "Spark",
						"endpoint": "https://rayfelipesynapseworkspace.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/SynapseDemoSprk",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.2",
						"nodeCount": 10,
						"cores": 4,
						"memory": 28,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "python"
							},
							"collapsed": false
						},
						"source": [
							"%%pyspark\r\n",
							"df = spark.read.load('abfss://rayfelipedlgen2filesystem@rayfelipedlgen2account.dfs.core.windows.net/Quickstarts/NYCTripSmall.parquet', format='parquet')\r\n",
							"display(df.limit(10))\r\n",
							"\r\n",
							""
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"df.printSchema()\r\n",
							"\r\n",
							"spark.sql(\"CREATE DATABASE IF NOT EXISTS nyctaxi\")\r\n",
							"df.write.mode(\"overwrite\").saveAsTable(\"nyctaxi.trip\")"
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Analyze the NYC Taxi data using Spark and notebooks\r\n",
							""
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"\r\n",
							"df = spark.sql(\"SELECT * FROM nyctaxi.trip\") \r\n",
							"display(df)"
						],
						"outputs": [],
						"execution_count": 4
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "python"
							},
							"collapsed": false
						},
						"source": [
							"%%pyspark\r\n",
							"df = spark.sql(\"\"\"\r\n",
							"   SELECT passenger_count,\r\n",
							"       SUM(trip_distance) as SumTripDistance,\r\n",
							"       AVG(trip_distance) as AvgTripDistance\r\n",
							"   FROM nyctaxi.trip\r\n",
							"   WHERE trip_distance > 0 AND passenger_count > 0\r\n",
							"   GROUP BY passenger_count\r\n",
							"   ORDER BY passenger_count\r\n",
							"\"\"\") \r\n",
							"display(df)\r\n",
							"df.write.mode(\"overwrite\").saveAsTable(\"nyctaxi.passengercountstats\")\r\n",
							""
						],
						"outputs": [],
						"execution_count": 5
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/1-Cannabis Acct Sites by Quarter')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "DCC"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "SynapseDemoSprk",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "dffd4662-fe00-4a37-8501-00a7de6ceeda"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/499bc654-f84c-46c2-952c-b30be508f78c/resourceGroups/Synapse-Demo/providers/Microsoft.Synapse/workspaces/rayfelipesynapseworkspace/bigDataPools/SynapseDemoSprk",
						"name": "SynapseDemoSprk",
						"type": "Spark",
						"endpoint": "https://rayfelipesynapseworkspace.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/SynapseDemoSprk",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.2",
						"nodeCount": 10,
						"cores": 4,
						"memory": 28,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "python"
							},
							"collapsed": false
						},
						"source": [
							"%%pyspark\r\n",
							"df = spark.read.load('abfss://dcc@datalakaeacctindemorg.dfs.core.windows.net/CannabisAccountSitesByQuarter.csv', format='csv', header='true')\r\n",
							"display(df.limit(10))\r\n",
							""
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"df.show()\r\n",
							"df.printSchema()\r\n",
							"df.select('Year').show()\r\n",
							"df.filter(df['Year'] == \"2018\").show()"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"pd_df = df.toPandas()\r\n",
							"pd_df.info()\r\n",
							"pd_df.describe()\r\n",
							"pd_df.head()"
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"pd_df['Year'] = pd_df['Year'].astype(int)\r\n",
							"pd_df['Quarter'] = pd_df['Quarter'].astype(int)\r\n",
							"pd_df['Active'] = pd_df['Active'].astype(int)\r\n",
							"pd_df['Ceased'] = pd_df['Ceased'].astype(int)\r\n",
							"\r\n",
							"import matplotlib.pyplot as plt\r\n",
							"pd_df.hist(bins=10, figsize=(15,8))\r\n",
							"plt.show()\r\n",
							"test"
						],
						"outputs": [],
						"execution_count": 4
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/2-Cannabis Sales by County')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "DCC"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "SynapseDemoSpk2",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "112g",
					"driverCores": 16,
					"executorMemory": "112g",
					"executorCores": 16,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "207ef1cd-4d43-4f54-9a60-31b9113da7ae"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/499bc654-f84c-46c2-952c-b30be508f78c/resourceGroups/Synapse-Demo/providers/Microsoft.Synapse/workspaces/rayfelipesynapseworkspace/bigDataPools/SynapseDemoSpk2",
						"name": "SynapseDemoSpk2",
						"type": "Spark",
						"endpoint": "https://rayfelipesynapseworkspace.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/SynapseDemoSpk2",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.2",
						"nodeCount": 10,
						"cores": 16,
						"memory": 112,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 15
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "python"
							},
							"collapsed": false
						},
						"source": [
							"%%pyspark\r\n",
							"df = spark.read.load('abfss://dcc@datalakaeacctindemorg.dfs.core.windows.net/CannabisSalesByCounty.csv', format='csv', header='true')\r\n",
							"display(df.limit(10))\r\n",
							""
						],
						"outputs": [],
						"execution_count": 6
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"df.show()\r\n",
							"df.printSchema()\r\n",
							"df.select('Calendar Year').show()\r\n",
							"df.filter(df['Calendar Year'] == \"2018\").show()"
						],
						"outputs": [],
						"execution_count": 7
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"pd_df = df.toPandas()\r\n",
							"pd_df.info()\r\n",
							"pd_df.describe()\r\n",
							"pd_df.head()"
						],
						"outputs": [],
						"execution_count": 8
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"pd_df['Calendar Year'] = pd_df['Calendar Year'].astype(int)\r\n",
							"pd_df['Quarter'] = pd_df['Quarter'].astype(int)\r\n",
							"pd_df['Per Capita Sales'] = pd_df['Per Capita Sales'].astype(float)\r\n",
							"pd_df['Total Taxable Sales'] = pd_df['Total Taxable Sales'].astype(float)\r\n",
							"\r\n",
							"import matplotlib.pyplot as plt\r\n",
							"pd_df.hist(bins=10, figsize=(15,8))\r\n",
							"plt.show()"
						],
						"outputs": [],
						"execution_count": 9
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/2-Data Exploration and ML Modeling - NYC taxi predict using Spark MLlib')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Quickstarts/4. AnalyzeUsingSparkPool"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "SynapseDemoSpk3",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "56g",
					"driverCores": 8,
					"executorMemory": "56g",
					"executorCores": 8,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "a92b9094-4e28-4fa3-9fd6-e93f62714a13"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/499bc654-f84c-46c2-952c-b30be508f78c/resourceGroups/Synapse-Demo/providers/Microsoft.Synapse/workspaces/rayfelipesynapseworkspace/bigDataPools/SynapseDemoSpk3",
						"name": "SynapseDemoSpk3",
						"type": "Spark",
						"endpoint": "https://rayfelipesynapseworkspace.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/SynapseDemoSpk3",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.2",
						"nodeCount": 10,
						"cores": 8,
						"memory": 56,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "markdown",
						"source": [
							"# Predict NYC Taxi Tips using Spark ML and Azure Open Datasets\n",
							"\n",
							"The notebook ingests, visualizes, prepares and then trains a model based on an Open Dataset that tracks NYC Yellow Taxi trips and various attributes around them.\n",
							"The goal is to predict for a given trip whether there will be a tip or not.\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"import matplotlib.pyplot as plt\n",
							"\n",
							"from pyspark.sql.functions import unix_timestamp\n",
							"\n",
							"from pyspark.sql import SparkSession\n",
							"from pyspark.sql.types import *\n",
							"from pyspark.sql.functions import *\n",
							"\n",
							"from pyspark.ml import Pipeline\n",
							"from pyspark.ml import PipelineModel\n",
							"from pyspark.ml.feature import RFormula\n",
							"from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorIndexer\n",
							"from pyspark.ml.classification import LogisticRegression\n",
							"from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
							"from pyspark.ml.evaluation import BinaryClassificationEvaluator"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Ingest Data¶ \n",
							"\n",
							"Get a sample data of nyc yellow taxi to make it faster/easier to evaluate different approaches to prep for the modelling phase later in the notebook."
						]
					},
					{
						"cell_type": "code",
						"source": [
							"# Import NYC yellow cab data from Azure Open Datasets\n",
							"from azureml.opendatasets import NycTlcYellow\n",
							"\n",
							"from datetime import datetime\n",
							"from dateutil import parser\n",
							"\n",
							"end_date = parser.parse('2018-05-08 00:00:00')\n",
							"start_date = parser.parse('2018-05-01 00:00:00')\n",
							"\n",
							"nyc_tlc = NycTlcYellow(start_date=start_date, end_date=end_date)\n",
							"nyc_tlc_df = nyc_tlc.to_spark_dataframe()"
						],
						"outputs": []
					},
					{
						"cell_type": "code",
						"source": [
							"#To make development easier, faster and less expensive downsample for now\n",
							"sampled_taxi_df = nyc_tlc_df.sample(True, 0.001, seed=1234)"
						],
						"outputs": []
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Exploratory Data Analysis\n",
							"\n",
							"Look at the data and evaluate its suitability for use in a model, do this via some basic charts focussed on tip values and relationships."
						]
					},
					{
						"cell_type": "code",
						"source": [
							"#The charting package needs a Pandas dataframe or numpy array do the conversion\n",
							"sampled_taxi_pd_df = sampled_taxi_df.toPandas()\n",
							"\n",
							"# Look at tips by amount count histogram\n",
							"ax1 = sampled_taxi_pd_df['tipAmount'].plot(kind='hist', bins=25, facecolor='lightblue')\n",
							"ax1.set_title('Tip amount distribution')\n",
							"ax1.set_xlabel('Tip Amount ($)')\n",
							"ax1.set_ylabel('Counts')\n",
							"plt.suptitle('')\n",
							"plt.show()\n",
							"\n",
							"# How many passengers tip'd by various amounts\n",
							"ax2 = sampled_taxi_pd_df.boxplot(column=['tipAmount'], by=['passengerCount'])\n",
							"ax2.set_title('Tip amount by Passenger count')\n",
							"ax2.set_xlabel('Passenger count') \n",
							"ax2.set_ylabel('Tip Amount ($)')\n",
							"plt.suptitle('')\n",
							"plt.show()\n",
							"\n",
							"# Look at the relationship between fare and tip amounts\n",
							"ax = sampled_taxi_pd_df.plot(kind='scatter', x= 'fareAmount', y = 'tipAmount', c='blue', alpha = 0.10, s=2.5*(sampled_taxi_pd_df['passengerCount']))\n",
							"ax.set_title('Tip amount by Fare amount')\n",
							"ax.set_xlabel('Fare Amount ($)')\n",
							"ax.set_ylabel('Tip Amount ($)')\n",
							"plt.axis([-2, 80, -2, 20])\n",
							"plt.suptitle('')\n",
							"plt.show()"
						],
						"outputs": []
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Data Prep and Featurization\n",
							"\n",
							"It's clear from the visualizations above that there are a bunch of outliers in the data. These will need to be filtered out in addition there are extra variables that are not going to be useful in the model we build at the end.\n",
							"\n",
							"Finally there is a need to create some new (derived) variables that will work better with the model.\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"taxi_df = sampled_taxi_df.select('totalAmount', 'fareAmount', 'tipAmount', 'paymentType', 'rateCodeId', 'passengerCount'\\\n",
							"                                , 'tripDistance', 'tpepPickupDateTime', 'tpepDropoffDateTime'\\\n",
							"                                , date_format('tpepPickupDateTime', 'hh').alias('pickupHour')\\\n",
							"                                , date_format('tpepPickupDateTime', 'EEEE').alias('weekdayString')\\\n",
							"                                , (unix_timestamp(col('tpepDropoffDateTime')) - unix_timestamp(col('tpepPickupDateTime'))).alias('tripTimeSecs')\\\n",
							"                                , (when(col('tipAmount') > 0, 1).otherwise(0)).alias('tipped')\n",
							"                                )\\\n",
							"                        .filter((sampled_taxi_df.passengerCount > 0) & (sampled_taxi_df.passengerCount < 8)\\\n",
							"                                & (sampled_taxi_df.tipAmount >= 0) & (sampled_taxi_df.tipAmount <= 25)\\\n",
							"                                & (sampled_taxi_df.fareAmount >= 1) & (sampled_taxi_df.fareAmount <= 250)\\\n",
							"                                & (sampled_taxi_df.tipAmount < sampled_taxi_df.fareAmount)\\\n",
							"                                & (sampled_taxi_df.tripDistance > 0) & (sampled_taxi_df.tripDistance <= 100)\\\n",
							"                                & (sampled_taxi_df.rateCodeId <= 5)\n",
							"                                & (sampled_taxi_df.paymentType.isin({\"1\", \"2\"}))\n",
							"                                )"
						],
						"outputs": []
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Data Prep and Featurization Part 2\n",
							"\n",
							"Having created new variables its now possible to drop the columns they were derived from so that the dataframe that goes into the model is the smallest in terms of number of variables, that is required.\n",
							"\n",
							"Also create some more features based on new columns from the first round.\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"taxi_featurised_df = taxi_df.select('totalAmount', 'fareAmount', 'tipAmount', 'paymentType', 'passengerCount'\\\n",
							"                                                , 'tripDistance', 'weekdayString', 'pickupHour','tripTimeSecs','tipped'\\\n",
							"                                                , when((taxi_df.pickupHour <= 6) | (taxi_df.pickupHour >= 20),\"Night\")\\\n",
							"                                                .when((taxi_df.pickupHour >= 7) & (taxi_df.pickupHour <= 10), \"AMRush\")\\\n",
							"                                                .when((taxi_df.pickupHour >= 11) & (taxi_df.pickupHour <= 15), \"Afternoon\")\\\n",
							"                                                .when((taxi_df.pickupHour >= 16) & (taxi_df.pickupHour <= 19), \"PMRush\")\\\n",
							"                                                .otherwise(0).alias('trafficTimeBins')\n",
							"                                              )\\\n",
							"                                       .filter((taxi_df.tripTimeSecs >= 30) & (taxi_df.tripTimeSecs <= 7200))"
						],
						"outputs": []
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Encoding\n",
							"\n",
							"Different ML algorithms support different types of input, for this example Logistic Regression is being used for Binary Classification. This means that any Categorical (string) variables must be converted to numbers.\n",
							"\n",
							"The process is not as simple as a \"map\" style function as the relationship between the numbers can introduce a bias in the resulting model, the approach is to index the variable and then encode using a std approach called One Hot Encoding.\n",
							"\n",
							"This approach requires the encoder to \"learn\"/fit a model over the data in the Spark instance and then transform based on what was learnt.\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"# The sample uses an algorithm that only works with numeric features convert them so they can be consumed\n",
							"sI1 = StringIndexer(inputCol=\"trafficTimeBins\", outputCol=\"trafficTimeBinsIndex\"); \n",
							"en1 = OneHotEncoder(dropLast=False, inputCol=\"trafficTimeBinsIndex\", outputCol=\"trafficTimeBinsVec\");\n",
							"sI2 = StringIndexer(inputCol=\"weekdayString\", outputCol=\"weekdayIndex\"); \n",
							"en2 = OneHotEncoder(dropLast=False, inputCol=\"weekdayIndex\", outputCol=\"weekdayVec\");\n",
							"\n",
							"# Create a new dataframe that has had the encodings applied\n",
							"encoded_final_df = Pipeline(stages=[sI1, en1, sI2, en2]).fit(taxi_featurised_df).transform(taxi_featurised_df)"
						],
						"outputs": []
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Generation of Testing and Training Data Sets\n",
							"Simple split, 70% for training and 30% for testing the model. Playing with this ratio may result in different models.\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"# Decide on the split between training and testing data from the dataframe \n",
							"trainingFraction = 0.7\n",
							"testingFraction = (1-trainingFraction)\n",
							"seed = 1234\n",
							"\n",
							"# Split the dataframe into test and training dataframes\n",
							"train_data_df, test_data_df = encoded_final_df.randomSplit([trainingFraction, testingFraction], seed=seed)"
						],
						"outputs": []
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Train the Model\n",
							"\n",
							"Train the Logistic Regression model and then evaluate it using Area under ROC as the metric."
						]
					},
					{
						"cell_type": "code",
						"source": [
							"## Create a new LR object for the model\n",
							"logReg = LogisticRegression(maxIter=10, regParam=0.3, labelCol = 'tipped')\n",
							"\n",
							"## The formula for the model\n",
							"classFormula = RFormula(formula=\"tipped ~ pickupHour + weekdayVec + passengerCount + tripTimeSecs + tripDistance + fareAmount + paymentType+ trafficTimeBinsVec\")\n",
							"\n",
							"## Undertake training and create an LR model\n",
							"lrModel = Pipeline(stages=[classFormula, logReg]).fit(train_data_df)\n",
							"\n",
							"## Saving the model is optional but its another for of inter session cache\n",
							"datestamp = datetime.now().strftime('%m-%d-%Y-%s');\n",
							"fileName = \"lrModel_\" + datestamp;\n",
							"logRegDirfilename = fileName;\n",
							"lrModel.save(logRegDirfilename)\n",
							"\n",
							"## Predict tip 1/0 (yes/no) on the test dataset, evaluation using AUROC\n",
							"predictions = lrModel.transform(test_data_df)\n",
							"predictionAndLabels = predictions.select(\"prediction\", \"label\").rdd\n",
							"metrics = BinaryClassificationMetrics(predictionAndLabels)\n",
							"print(\"Area under ROC = %s\" % metrics.areaUnderROC)"
						],
						"outputs": []
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Evaluate and Visualize\n",
							"\n",
							"Plot the actual curve to develop a better understanding of the model.\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"## Plot the ROC curve, no need for pandas as this uses the modelSummary object\n",
							"modelSummary = lrModel.stages[-1].summary\n",
							"\n",
							"plt.plot([0, 1], [0, 1], 'r--')\n",
							"plt.plot(modelSummary.roc.select('FPR').collect(),\n",
							"         modelSummary.roc.select('TPR').collect())\n",
							"plt.xlabel('False Positive Rate')\n",
							"plt.ylabel('True Positive Rate')\n",
							"plt.show()"
						],
						"outputs": []
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/3-Cannabis Tax Cultivation Excise Revenue')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "DCC"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "SynapseDemoSprk",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "d3fbc79b-587e-4a02-82ba-0cbb3c5f4bf3"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/499bc654-f84c-46c2-952c-b30be508f78c/resourceGroups/Synapse-Demo/providers/Microsoft.Synapse/workspaces/rayfelipesynapseworkspace/bigDataPools/SynapseDemoSprk",
						"name": "SynapseDemoSprk",
						"type": "Spark",
						"endpoint": "https://rayfelipesynapseworkspace.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/SynapseDemoSprk",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.2",
						"nodeCount": 10,
						"cores": 4,
						"memory": 28,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 15
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "python"
							},
							"collapsed": false
						},
						"source": [
							"%%pyspark\r\n",
							"df = spark.read.load('abfss://dcc@datalakaeacctindemorg.dfs.core.windows.net/CannabisTaxCultivationExciseRevenue.csv', format='csv', header='true')\r\n",
							"display(df.limit(10))\r\n",
							""
						],
						"outputs": [],
						"execution_count": 16
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"df.show()\r\n",
							"df.printSchema()\r\n",
							"df.select('Fiscal Year To').show()\r\n",
							"df.filter(df['Fiscal Year To'] == \"2018\").show()"
						],
						"outputs": [],
						"execution_count": 17
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"pd_df = df.toPandas()\r\n",
							"pd_df.info()\r\n",
							"pd_df.describe()\r\n",
							"pd_df.head()"
						],
						"outputs": [],
						"execution_count": 18
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"pd_df['Fiscal Year From'] = pd_df['Fiscal Year From'].astype(int)\r\n",
							"pd_df['Fiscal Year To'] = pd_df['Fiscal Year To'].astype(int)\r\n",
							"pd_df['Number of Returns Filed'] = pd_df['Number of Returns Filed'].astype(int)\r\n",
							"pd_df['1. Total Average Market Price on Sales/Transfers of Cannabis'] = pd_df['1. Total Average Market Price on Sales/Transfers of Cannabis'].astype(float)\r\n",
							"pd_df['3. Excise Tax Due'] = pd_df['3. Excise Tax Due'].astype(float)\r\n",
							"pd_df['16. Total Cannabis Excise Tax Due'] = pd_df['16. Total Cannabis Excise Tax Due'].astype(float)\r\n",
							"\r\n",
							"# pd_df['xx'] = pd_df['xx'].astype(int)\r\n",
							"\r\n",
							"\r\n",
							"\r\n",
							"import matplotlib.pyplot as plt\r\n",
							"pd_df.hist(bins=10, figsize=(20,10))\r\n",
							"plt.show()\r\n",
							"\r\n",
							"pd_df.plot(figsize=(10,5))\r\n",
							"plt.show()"
						],
						"outputs": [],
						"execution_count": 19
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# pd_df.plot(x = 'Fiscal Year To', y = '16. Total Cannabis Excise Tax Due', kind = 'line')\r\n",
							"# Core_Dataframe.plot(x ='age', y='py-score', kind = 'bar')\r\n",
							"pd_df.plot(figsize=(10,5))\r\n",
							"pd_df.plot.scatter(x='Fiscal Year To', y='16. Total Cannabis Excise Tax Due', figsize=(5,5))\r\n",
							"pd_df.plot.scatter(x='Number of Returns Filed', y='16. Total Cannabis Excise Tax Due', figsize=(5,5))\r\n",
							"\r\n",
							"plt.show()"
						],
						"outputs": [],
						"execution_count": 20
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/4-Cannabis Tax Revenues')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "DCC"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "SynapseDemoSpk2",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "112g",
					"driverCores": 16,
					"executorMemory": "112g",
					"executorCores": 16,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "c4af88c6-9118-4da0-9b33-77b7b03dff3b"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/499bc654-f84c-46c2-952c-b30be508f78c/resourceGroups/Synapse-Demo/providers/Microsoft.Synapse/workspaces/rayfelipesynapseworkspace/bigDataPools/SynapseDemoSpk2",
						"name": "SynapseDemoSpk2",
						"type": "Spark",
						"endpoint": "https://rayfelipesynapseworkspace.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/SynapseDemoSpk2",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.2",
						"nodeCount": 10,
						"cores": 16,
						"memory": 112,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 60
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "python"
							},
							"collapsed": false
						},
						"source": [
							"%%pyspark\r\n",
							"df = spark.read.load('abfss://dcc@datalakaeacctindemorg.dfs.core.windows.net/CannabisTaxRevenues.csv', format='csv', header='true')\r\n",
							"display(df.limit(10))\r\n",
							""
						],
						"outputs": [],
						"execution_count": 22
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"df.show()\r\n",
							"df.printSchema()\r\n",
							"df.select('Calendar_Year').show()\r\n",
							"df.filter(df['Calendar_Year'] == \"2018\").show()"
						],
						"outputs": [],
						"execution_count": 23
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"pd_df = df.toPandas()\r\n",
							"pd_df.info()\r\n",
							"pd_df.describe()\r\n",
							"pd_df.head()"
						],
						"outputs": [],
						"execution_count": 24
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"pd_df['Calendar_Year'] = pd_df['Calendar_Year'].astype(int)\r\n",
							"pd_df['Quarter'] = pd_df['Quarter'].astype(str)\r\n",
							"pd_df['Excise_Tax'] = pd_df['Excise_Tax'].astype(int)\r\n",
							"pd_df['Cultivation_Tax'] = pd_df['Cultivation_Tax'].astype(str)\r\n",
							"pd_df['Total_Tax'] = pd_df['Total_Tax'].astype(int)\r\n",
							"pd_df['Taxable_Sales'] = pd_df['Taxable_Sales'].astype(int)\r\n",
							"\r\n",
							"import matplotlib.pyplot as plt\r\n",
							"pd_df.hist(bins=10, figsize=(15,8))\r\n",
							"plt.show()\r\n",
							""
						],
						"outputs": [],
						"execution_count": 25
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"pd_df.plot(figsize=(10,5))\r\n",
							"pd_df.plot.scatter(x='Excise_Tax', y='Calendar_Year', figsize=(5,5))\r\n",
							"# pd_df.plot.scatter(x='Number of Returns Filed', y='16. Total Cannabis Excise Tax Due', figsize=(5,5))\r\n",
							"\r\n",
							"plt.show()"
						],
						"outputs": [],
						"execution_count": 26
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"df.printSchema()\r\n",
							"# display(df.limit(10))\r\n",
							"display(df)\r\n",
							"spark.sql(\"CREATE DATABASE IF NOT EXISTS cannabis\")\r\n",
							"df.write.mode(\"overwrite\").saveAsTable(\"cannabis.taxrevenue\")"
						],
						"outputs": [],
						"execution_count": 27
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "python"
							},
							"collapsed": false
						},
						"source": [
							"%%pyspark\r\n",
							"sparksql_df = spark.sql(\"\"\"\r\n",
							"   SELECT *\r\n",
							"   FROM cannabis.taxrevenue\r\n",
							"   WHERE Calendar_Year == \"2019\"\r\n",
							"\"\"\") \r\n",
							"display(sparksql_df)\r\n",
							"sparksql_df.write.mode(\"overwrite\").saveAsTable(\"cannabis.taxrevenue2019\")"
						],
						"outputs": [],
						"execution_count": 28
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AnalyzeNYCTaxiDataWithSparkPool')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Quickstarts/4. AnalyzeUsingSparkPool"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "SynapseDemoSprk",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "e6ab386d-aa06-42f4-9734-beef0ddc30b4"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/499bc654-f84c-46c2-952c-b30be508f78c/resourceGroups/Synapse-Demo/providers/Microsoft.Synapse/workspaces/rayfelipesynapseworkspace/bigDataPools/SynapseDemoSprk",
						"name": "SynapseDemoSprk",
						"type": "Spark",
						"endpoint": "https://rayfelipesynapseworkspace.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/SynapseDemoSprk",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.2",
						"nodeCount": 10,
						"cores": 4,
						"memory": 28,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "python"
							},
							"collapsed": false
						},
						"source": [
							"%%pyspark\r\n",
							"df = spark.read.load('abfss://rayfelipedlgen2filesystem@rayfelipedlgen2account.dfs.core.windows.net/Quickstarts/NYCTripSmall.parquet', format='parquet')\r\n",
							"display(df.limit(10))\r\n",
							"\r\n",
							""
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"df.printSchema()\r\n",
							"\r\n",
							"spark.sql(\"CREATE DATABASE IF NOT EXISTS nyctaxi\")\r\n",
							"df.write.mode(\"overwrite\").saveAsTable(\"nyctaxi.trip\")"
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Analyze the NYC Taxi data using Spark and notebooks\r\n",
							""
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"\r\n",
							"df = spark.sql(\"SELECT * FROM nyctaxi.trip\") \r\n",
							"display(df)"
						],
						"outputs": [],
						"execution_count": 6
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "python"
							},
							"collapsed": false
						},
						"source": [
							"%%pyspark\r\n",
							"df = spark.sql(\"\"\"\r\n",
							"   SELECT passenger_count,\r\n",
							"       SUM(trip_distance) as SumTripDistance,\r\n",
							"       AVG(trip_distance) as AvgTripDistance\r\n",
							"   FROM nyctaxi.trip\r\n",
							"   WHERE trip_distance > 0 AND passenger_count > 0\r\n",
							"   GROUP BY passenger_count\r\n",
							"   ORDER BY passenger_count\r\n",
							"\"\"\") \r\n",
							"display(df)\r\n",
							"df.write.mode(\"overwrite\").saveAsTable(\"nyctaxi.passengercountstats\")\r\n",
							""
						],
						"outputs": [],
						"execution_count": 8
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/BSCC Notebook')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "bce5f04a-eabe-4e94-8107-5bc64e96ee2a"
					}
				},
				"metadata": {
					"saveOutput": true,
					"synapse_widget": {
						"version": "0.1"
					},
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "python"
					},
					"language_info": {
						"name": "python"
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"from pyspark.sql import SparkSession\r\n",
							"from pyspark.sql.types import *\r\n",
							"from pyspark.sql.functions import col, year, month, dayofmonth, unix_timestamp, round, when\r\n",
							"from datetime import datetime\r\n",
							"\r\n",
							"# Replace your storage location\r\n",
							"covid19casesdemographicsdf = spark.read.load('abfss://bsccsandboxdlgen2filesystem@bsccsandboxdlgen2acct.dfs.core.windows.net/bscc_datasets/covid19casesdemographics.csv', \r\n",
							"format='csv', header=True)\r\n",
							"\r\n",
							"#covid19casesdemographicsdf = spark.read.load('abfss://bsccdemodlgen2filesystem@bsccdemodlgen2acct.dfs.core.windows.net/bscc_dataset/covid19casesdemographics.csv', \r\n",
							"#format='csv', header=True)\r\n",
							"\r\n",
							"covid19casesdemographicsdf = covid19casesdemographicsdf.where(col('deaths') > 0)\r\n",
							"covid19casesdemographicsdf = covid19casesdemographicsdf.where(col('demographic_category') == 'Gender')\r\n",
							"\r\n",
							"spark.sql(\"CREATE DATABASE IF NOT EXISTS bcc_data_lake\")\r\n",
							"covid19casesdemographicsdf.repartition(4).write.mode(\"overwrite\").saveAsTable(\"bcc_data_lake.covid_bygender\")\r\n",
							"\r\n",
							"print(\"Extracted & cleaned data\")\r\n",
							"\r\n",
							"#covid19casesdemographicsdf = covid19casesdemographicsdf.select(col(\"demographic_category\"))\r\n",
							"\r\n",
							"display(covid19casesdemographicsdf.limit(1000))\r\n",
							"\r\n",
							"#covid19casesdemographicsdf.printSchema()\r\n",
							"\r\n",
							""
						],
						"outputs": []
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Caltrans Traffic')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "SynapseDemoSprk",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "1a13c762-c56e-4b36-a02e-ea0cff1759f3"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/499bc654-f84c-46c2-952c-b30be508f78c/resourceGroups/Synapse-Demo/providers/Microsoft.Synapse/workspaces/rayfelipesynapseworkspace/bigDataPools/SynapseDemoSprk",
						"name": "SynapseDemoSprk",
						"type": "Spark",
						"endpoint": "https://rayfelipesynapseworkspace.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/SynapseDemoSprk",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.2",
						"nodeCount": 10,
						"cores": 4,
						"memory": 28,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "python"
							},
							"collapsed": false
						},
						"source": [
							"%%pyspark\r\n",
							"df = spark.read.load('abfss://rayfelipedlgen2filesystem@rayfelipedlgen2account.dfs.core.windows.net/Caltrans/traffic.csv', format='csv'\r\n",
							"## If header exists uncomment line below\r\n",
							"##, header=True\r\n",
							")\r\n",
							"display(df.limit(5))\r\n",
							"\r\n",
							"print(df.show())\r\n",
							"print(df.printSchema())\r\n",
							"df.select(\"_c2\").show()\r\n",
							"df.filter(df[2] == \"10\").show()\r\n",
							"df.groupBy(\"_c2\").count().show()\r\n",
							"print(df[3])\r\n",
							"\r\n",
							"import pandas as pd\r\n",
							"\r\n",
							"from pandas import read_csv\r\n",
							"from pandas import set_option\r\n",
							"\r\n",
							"# CAL TRANS DATA SET\r\n",
							"path = 'abfss://rayfelipedlgen2filesystem@rayfelipedlgen2account.dfs.core.windows.net/Caltrans/traffic.csv'\r\n",
							"headernames = ['DateTime', 'Junction', 'Vehicles', 'ID']\r\n",
							"data = read_csv(path, names=headernames)\r\n",
							"set_option('display.width', 100)\r\n",
							"set_option('precision', 2)\r\n",
							"\r\n",
							"print(data.head(10))\r\n",
							"print(data.shape)\r\n",
							"print(data.describe())\r\n",
							"\r\n",
							"#correlations = data.corr(method='pearson')\r\n",
							"#print(\"CORRELATIONS:\")\r\n",
							"#print(correlations)"
						],
						"outputs": [],
						"execution_count": 2
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Cannabis Acct Sites by Quarter')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "DCC"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "SynapseDemoSprk",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "7580c071-26e8-4cd6-8b50-17db7719013f"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/499bc654-f84c-46c2-952c-b30be508f78c/resourceGroups/Synapse-Demo/providers/Microsoft.Synapse/workspaces/rayfelipesynapseworkspace/bigDataPools/SynapseDemoSprk",
						"name": "SynapseDemoSprk",
						"type": "Spark",
						"endpoint": "https://rayfelipesynapseworkspace.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/SynapseDemoSprk",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.2",
						"nodeCount": 10,
						"cores": 4,
						"memory": 28,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "python"
							},
							"collapsed": false
						},
						"source": [
							"%%pyspark\r\n",
							"df = spark.read.load('abfss://dcc@datalakaeacctindemorg.dfs.core.windows.net/CannabisAccountSitesByQuarter.csv', format='csv', header='true')\r\n",
							"display(df.limit(10))\r\n",
							""
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"df.show()\r\n",
							"df.printSchema()\r\n",
							"df.select('Year').show()\r\n",
							"df.filter(df['Year'] == \"2018\").show()"
						],
						"outputs": [],
						"execution_count": 40
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"pd_df = df.toPandas()\r\n",
							"pd_df.info()\r\n",
							"pd_df.describe()\r\n",
							"pd_df.head()"
						],
						"outputs": [],
						"execution_count": 41
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"pd_df['Year'] = pd_df['Year'].astype(int)\r\n",
							"pd_df['Quarter'] = pd_df['Quarter'].astype(int)\r\n",
							"pd_df['Active'] = pd_df['Active'].astype(int)\r\n",
							"pd_df['Ceased'] = pd_df['Ceased'].astype(int)\r\n",
							"\r\n",
							"import matplotlib.pyplot as plt\r\n",
							"pd_df.hist(bins=10, figsize=(15,8))\r\n",
							"plt.show()"
						],
						"outputs": [],
						"execution_count": 53
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Cannabis Sales by County')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "DCC"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "SynapseDemoSpk2",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "112g",
					"driverCores": 16,
					"executorMemory": "112g",
					"executorCores": 16,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "82d18a4c-6c48-4f4d-b487-fca34cfbd40b"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/499bc654-f84c-46c2-952c-b30be508f78c/resourceGroups/Synapse-Demo/providers/Microsoft.Synapse/workspaces/rayfelipesynapseworkspace/bigDataPools/SynapseDemoSpk2",
						"name": "SynapseDemoSpk2",
						"type": "Spark",
						"endpoint": "https://rayfelipesynapseworkspace.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/SynapseDemoSpk2",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.2",
						"nodeCount": 10,
						"cores": 16,
						"memory": 112,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 15
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "python"
							},
							"collapsed": false
						},
						"source": [
							"%%pyspark\r\n",
							"df = spark.read.load('abfss://dcc@datalakaeacctindemorg.dfs.core.windows.net/CannabisSalesByCounty.csv', format='csv', header='true')\r\n",
							"display(df.limit(10))\r\n",
							""
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"df.show()\r\n",
							"df.printSchema()\r\n",
							"df.select('Calendar Year').show()\r\n",
							"df.filter(df['Calendar Year'] == \"2018\").show()"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"pd_df = df.toPandas()\r\n",
							"pd_df.info()\r\n",
							"pd_df.describe()\r\n",
							"pd_df.head()"
						],
						"outputs": [],
						"execution_count": 5
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"pd_df['Calendar Year'] = pd_df['Calendar Year'].astype(int)\r\n",
							"pd_df['Quarter'] = pd_df['Quarter'].astype(int)\r\n",
							"pd_df['Per Capita Sales'] = pd_df['Per Capita Sales'].astype(float)\r\n",
							"pd_df['Total Taxable Sales'] = pd_df['Total Taxable Sales'].astype(float)\r\n",
							"\r\n",
							"import matplotlib.pyplot as plt\r\n",
							"pd_df.hist(bins=10, figsize=(15,8))\r\n",
							"plt.show()"
						],
						"outputs": [],
						"execution_count": 4
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Cannabis Tax Cultivation Excise Revenue')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "DCC"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "SynapseDemoSpk2",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "112g",
					"driverCores": 16,
					"executorMemory": "112g",
					"executorCores": 16,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "be6dc2b6-867f-47ec-905f-026fbb4e6bc1"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/499bc654-f84c-46c2-952c-b30be508f78c/resourceGroups/Synapse-Demo/providers/Microsoft.Synapse/workspaces/rayfelipesynapseworkspace/bigDataPools/SynapseDemoSpk2",
						"name": "SynapseDemoSpk2",
						"type": "Spark",
						"endpoint": "https://rayfelipesynapseworkspace.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/SynapseDemoSpk2",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.2",
						"nodeCount": 10,
						"cores": 16,
						"memory": 112,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 15
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "python"
							},
							"collapsed": false
						},
						"source": [
							"%%pyspark\r\n",
							"df = spark.read.load('abfss://dcc@datalakaeacctindemorg.dfs.core.windows.net/CannabisTaxCultivationExciseRevenue.csv', format='csv', header='true')\r\n",
							"display(df.limit(10))\r\n",
							""
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"df.show()\r\n",
							"df.printSchema()\r\n",
							"df.select('Fiscal Year To').show()\r\n",
							"df.filter(df['Fiscal Year To'] == \"2018\").show()"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"pd_df = df.toPandas()\r\n",
							"pd_df.info()\r\n",
							"pd_df.describe()\r\n",
							"pd_df.head()"
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"pd_df['Fiscal Year From'] = pd_df['Fiscal Year From'].astype(int)\r\n",
							"pd_df['Fiscal Year To'] = pd_df['Fiscal Year To'].astype(int)\r\n",
							"pd_df['Number of Returns Filed'] = pd_df['Number of Returns Filed'].astype(int)\r\n",
							"pd_df['1. Total Average Market Price on Sales/Transfers of Cannabis'] = pd_df['1. Total Average Market Price on Sales/Transfers of Cannabis'].astype(float)\r\n",
							"pd_df['3. Excise Tax Due'] = pd_df['3. Excise Tax Due'].astype(float)\r\n",
							"pd_df['16. Total Cannabis Excise Tax Due'] = pd_df['16. Total Cannabis Excise Tax Due'].astype(float)\r\n",
							"\r\n",
							"# pd_df['xx'] = pd_df['xx'].astype(int)\r\n",
							"\r\n",
							"\r\n",
							"\r\n",
							"import matplotlib.pyplot as plt\r\n",
							"pd_df.hist(bins=10, figsize=(20,10))\r\n",
							"plt.show()\r\n",
							"\r\n",
							"pd_df.plot(figsize=(10,5))\r\n",
							"plt.show()"
						],
						"outputs": [],
						"execution_count": 34
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# pd_df.plot(x = 'Fiscal Year To', y = '16. Total Cannabis Excise Tax Due', kind = 'line')\r\n",
							"# Core_Dataframe.plot(x ='age', y='py-score', kind = 'bar')\r\n",
							"pd_df.plot(figsize=(10,5))\r\n",
							"pd_df.plot.scatter(x='Fiscal Year To', y='16. Total Cannabis Excise Tax Due', figsize=(5,5))\r\n",
							"pd_df.plot.scatter(x='Number of Returns Filed', y='16. Total Cannabis Excise Tax Due', figsize=(5,5))\r\n",
							"\r\n",
							"plt.show()"
						],
						"outputs": [],
						"execution_count": 33
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Cannabis Tax Revenues')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "DCC"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "SynapseDemoSpk2",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "112g",
					"driverCores": 16,
					"executorMemory": "112g",
					"executorCores": 16,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "e4bf0517-0e6a-4c24-a62b-97484ec80f38"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/499bc654-f84c-46c2-952c-b30be508f78c/resourceGroups/Synapse-Demo/providers/Microsoft.Synapse/workspaces/rayfelipesynapseworkspace/bigDataPools/SynapseDemoSpk2",
						"name": "SynapseDemoSpk2",
						"type": "Spark",
						"endpoint": "https://rayfelipesynapseworkspace.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/SynapseDemoSpk2",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.2",
						"nodeCount": 10,
						"cores": 16,
						"memory": 112,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 15
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "python"
							},
							"collapsed": false
						},
						"source": [
							"%%pyspark\r\n",
							"df = spark.read.load('abfss://dcc@datalakaeacctindemorg.dfs.core.windows.net/CannabisTaxRevenues.csv', format='csv', header='true')\r\n",
							"display(df.limit(10))\r\n",
							""
						],
						"outputs": [],
						"execution_count": 46
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"df.show()\r\n",
							"df.printSchema()\r\n",
							"df.select('Calendar_Year').show()\r\n",
							"df.filter(df['Calendar_Year'] == \"2018\").show()"
						],
						"outputs": [],
						"execution_count": 47
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"pd_df = df.toPandas()\r\n",
							"pd_df.info()\r\n",
							"pd_df.describe()\r\n",
							"pd_df.head()"
						],
						"outputs": [],
						"execution_count": 48
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"pd_df['Calendar_Year'] = pd_df['Calendar_Year'].astype(int)\r\n",
							"pd_df['Quarter'] = pd_df['Quarter'].astype(str)\r\n",
							"pd_df['Excise_Tax'] = pd_df['Excise_Tax'].astype(int)\r\n",
							"pd_df['Cultivation_Tax'] = pd_df['Cultivation_Tax'].astype(str)\r\n",
							"pd_df['Total_Tax'] = pd_df['Total_Tax'].astype(int)\r\n",
							"pd_df['Taxable_Sales'] = pd_df['Taxable_Sales'].astype(int)\r\n",
							"\r\n",
							"import matplotlib.pyplot as plt\r\n",
							"pd_df.hist(bins=10, figsize=(15,8))\r\n",
							"plt.show()\r\n",
							""
						],
						"outputs": [],
						"execution_count": 49
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"pd_df.plot(figsize=(10,5))\r\n",
							"pd_df.plot.scatter(x='Excise_Tax', y='Calendar_Year', figsize=(5,5))\r\n",
							"# pd_df.plot.scatter(x='Number of Returns Filed', y='16. Total Cannabis Excise Tax Due', figsize=(5,5))\r\n",
							"\r\n",
							"plt.show()"
						],
						"outputs": [],
						"execution_count": 50
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"df.printSchema()\r\n",
							"# display(df.limit(10))\r\n",
							"display(df)\r\n",
							"spark.sql(\"CREATE DATABASE IF NOT EXISTS cannabis\")\r\n",
							"df.write.mode(\"overwrite\").saveAsTable(\"cannabis.taxrevenue\")"
						],
						"outputs": [],
						"execution_count": 51
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "python"
							},
							"collapsed": false
						},
						"source": [
							"%%pyspark\r\n",
							"sparksql_df = spark.sql(\"\"\"\r\n",
							"   SELECT *\r\n",
							"   FROM cannabis.taxrevenue\r\n",
							"   WHERE Calendar_Year == \"2019\"\r\n",
							"\"\"\") \r\n",
							"display(sparksql_df)\r\n",
							"df.write.mode(\"overwrite\").saveAsTable(\"cannabis.taxrevenue2019\")"
						],
						"outputs": [],
						"execution_count": 52
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Data Exploration and ML Modeling - NYC taxi predict using Spark MLlib')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Quickstarts/4. AnalyzeUsingSparkPool"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "SynapseDemoSpk2",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "112g",
					"driverCores": 16,
					"executorMemory": "112g",
					"executorCores": 16,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "86ec15a6-4cad-423f-9db8-2e11cea19dc1"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/499bc654-f84c-46c2-952c-b30be508f78c/resourceGroups/Synapse-Demo/providers/Microsoft.Synapse/workspaces/rayfelipesynapseworkspace/bigDataPools/SynapseDemoSpk2",
						"name": "SynapseDemoSpk2",
						"type": "Spark",
						"endpoint": "https://rayfelipesynapseworkspace.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/SynapseDemoSpk2",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.2",
						"nodeCount": 10,
						"cores": 16,
						"memory": 112,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "markdown",
						"source": [
							"# Predict NYC Taxi Tips using Spark ML and Azure Open Datasets\n",
							"\n",
							"The notebook ingests, visualizes, prepares and then trains a model based on an Open Dataset that tracks NYC Yellow Taxi trips and various attributes around them.\n",
							"The goal is to predict for a given trip whether there will be a tip or not.\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"import matplotlib.pyplot as plt\n",
							"\n",
							"from pyspark.sql.functions import unix_timestamp\n",
							"\n",
							"from pyspark.sql import SparkSession\n",
							"from pyspark.sql.types import *\n",
							"from pyspark.sql.functions import *\n",
							"\n",
							"from pyspark.ml import Pipeline\n",
							"from pyspark.ml import PipelineModel\n",
							"from pyspark.ml.feature import RFormula\n",
							"from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorIndexer\n",
							"from pyspark.ml.classification import LogisticRegression\n",
							"from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
							"from pyspark.ml.evaluation import BinaryClassificationEvaluator"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Ingest Data¶ \n",
							"\n",
							"Get a sample data of nyc yellow taxi to make it faster/easier to evaluate different approaches to prep for the modelling phase later in the notebook."
						]
					},
					{
						"cell_type": "code",
						"source": [
							"# Import NYC yellow cab data from Azure Open Datasets\n",
							"from azureml.opendatasets import NycTlcYellow\n",
							"\n",
							"from datetime import datetime\n",
							"from dateutil import parser\n",
							"\n",
							"end_date = parser.parse('2018-05-08 00:00:00')\n",
							"start_date = parser.parse('2018-05-01 00:00:00')\n",
							"\n",
							"nyc_tlc = NycTlcYellow(start_date=start_date, end_date=end_date)\n",
							"nyc_tlc_df = nyc_tlc.to_spark_dataframe()"
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "code",
						"source": [
							"#To make development easier, faster and less expensive downsample for now\n",
							"sampled_taxi_df = nyc_tlc_df.sample(True, 0.001, seed=1234)"
						],
						"outputs": [],
						"execution_count": 4
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Exploratory Data Analysis\n",
							"\n",
							"Look at the data and evaluate its suitability for use in a model, do this via some basic charts focussed on tip values and relationships."
						]
					},
					{
						"cell_type": "code",
						"source": [
							"#The charting package needs a Pandas dataframe or numpy array do the conversion\n",
							"sampled_taxi_pd_df = sampled_taxi_df.toPandas()\n",
							"\n",
							"# Look at tips by amount count histogram\n",
							"ax1 = sampled_taxi_pd_df['tipAmount'].plot(kind='hist', bins=25, facecolor='lightblue')\n",
							"ax1.set_title('Tip amount distribution')\n",
							"ax1.set_xlabel('Tip Amount ($)')\n",
							"ax1.set_ylabel('Counts')\n",
							"plt.suptitle('')\n",
							"plt.show()\n",
							"\n",
							"# How many passengers tip'd by various amounts\n",
							"ax2 = sampled_taxi_pd_df.boxplot(column=['tipAmount'], by=['passengerCount'])\n",
							"ax2.set_title('Tip amount by Passenger count')\n",
							"ax2.set_xlabel('Passenger count') \n",
							"ax2.set_ylabel('Tip Amount ($)')\n",
							"plt.suptitle('')\n",
							"plt.show()\n",
							"\n",
							"# Look at the relationship between fare and tip amounts\n",
							"ax = sampled_taxi_pd_df.plot(kind='scatter', x= 'fareAmount', y = 'tipAmount', c='blue', alpha = 0.10, s=2.5*(sampled_taxi_pd_df['passengerCount']))\n",
							"ax.set_title('Tip amount by Fare amount')\n",
							"ax.set_xlabel('Fare Amount ($)')\n",
							"ax.set_ylabel('Tip Amount ($)')\n",
							"plt.axis([-2, 80, -2, 20])\n",
							"plt.suptitle('')\n",
							"plt.show()"
						],
						"outputs": [],
						"execution_count": 5
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Data Prep and Featurization\n",
							"\n",
							"It's clear from the visualizations above that there are a bunch of outliers in the data. These will need to be filtered out in addition there are extra variables that are not going to be useful in the model we build at the end.\n",
							"\n",
							"Finally there is a need to create some new (derived) variables that will work better with the model.\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"taxi_df = sampled_taxi_df.select('totalAmount', 'fareAmount', 'tipAmount', 'paymentType', 'rateCodeId', 'passengerCount'\\\n",
							"                                , 'tripDistance', 'tpepPickupDateTime', 'tpepDropoffDateTime'\\\n",
							"                                , date_format('tpepPickupDateTime', 'hh').alias('pickupHour')\\\n",
							"                                , date_format('tpepPickupDateTime', 'EEEE').alias('weekdayString')\\\n",
							"                                , (unix_timestamp(col('tpepDropoffDateTime')) - unix_timestamp(col('tpepPickupDateTime'))).alias('tripTimeSecs')\\\n",
							"                                , (when(col('tipAmount') > 0, 1).otherwise(0)).alias('tipped')\n",
							"                                )\\\n",
							"                        .filter((sampled_taxi_df.passengerCount > 0) & (sampled_taxi_df.passengerCount < 8)\\\n",
							"                                & (sampled_taxi_df.tipAmount >= 0) & (sampled_taxi_df.tipAmount <= 25)\\\n",
							"                                & (sampled_taxi_df.fareAmount >= 1) & (sampled_taxi_df.fareAmount <= 250)\\\n",
							"                                & (sampled_taxi_df.tipAmount < sampled_taxi_df.fareAmount)\\\n",
							"                                & (sampled_taxi_df.tripDistance > 0) & (sampled_taxi_df.tripDistance <= 100)\\\n",
							"                                & (sampled_taxi_df.rateCodeId <= 5)\n",
							"                                & (sampled_taxi_df.paymentType.isin({\"1\", \"2\"}))\n",
							"                                )"
						],
						"outputs": [],
						"execution_count": 6
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Data Prep and Featurization Part 2\n",
							"\n",
							"Having created new variables its now possible to drop the columns they were derived from so that the dataframe that goes into the model is the smallest in terms of number of variables, that is required.\n",
							"\n",
							"Also create some more features based on new columns from the first round.\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"taxi_featurised_df = taxi_df.select('totalAmount', 'fareAmount', 'tipAmount', 'paymentType', 'passengerCount'\\\n",
							"                                                , 'tripDistance', 'weekdayString', 'pickupHour','tripTimeSecs','tipped'\\\n",
							"                                                , when((taxi_df.pickupHour <= 6) | (taxi_df.pickupHour >= 20),\"Night\")\\\n",
							"                                                .when((taxi_df.pickupHour >= 7) & (taxi_df.pickupHour <= 10), \"AMRush\")\\\n",
							"                                                .when((taxi_df.pickupHour >= 11) & (taxi_df.pickupHour <= 15), \"Afternoon\")\\\n",
							"                                                .when((taxi_df.pickupHour >= 16) & (taxi_df.pickupHour <= 19), \"PMRush\")\\\n",
							"                                                .otherwise(0).alias('trafficTimeBins')\n",
							"                                              )\\\n",
							"                                       .filter((taxi_df.tripTimeSecs >= 30) & (taxi_df.tripTimeSecs <= 7200))"
						],
						"outputs": [],
						"execution_count": 7
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Encoding\n",
							"\n",
							"Different ML algorithms support different types of input, for this example Logistic Regression is being used for Binary Classification. This means that any Categorical (string) variables must be converted to numbers.\n",
							"\n",
							"The process is not as simple as a \"map\" style function as the relationship between the numbers can introduce a bias in the resulting model, the approach is to index the variable and then encode using a std approach called One Hot Encoding.\n",
							"\n",
							"This approach requires the encoder to \"learn\"/fit a model over the data in the Spark instance and then transform based on what was learnt.\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"# The sample uses an algorithm that only works with numeric features convert them so they can be consumed\n",
							"sI1 = StringIndexer(inputCol=\"trafficTimeBins\", outputCol=\"trafficTimeBinsIndex\"); \n",
							"en1 = OneHotEncoder(dropLast=False, inputCol=\"trafficTimeBinsIndex\", outputCol=\"trafficTimeBinsVec\");\n",
							"sI2 = StringIndexer(inputCol=\"weekdayString\", outputCol=\"weekdayIndex\"); \n",
							"en2 = OneHotEncoder(dropLast=False, inputCol=\"weekdayIndex\", outputCol=\"weekdayVec\");\n",
							"\n",
							"# Create a new dataframe that has had the encodings applied\n",
							"encoded_final_df = Pipeline(stages=[sI1, en1, sI2, en2]).fit(taxi_featurised_df).transform(taxi_featurised_df)"
						],
						"outputs": [],
						"execution_count": 8
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Generation of Testing and Training Data Sets\n",
							"Simple split, 70% for training and 30% for testing the model. Playing with this ratio may result in different models.\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"# Decide on the split between training and testing data from the dataframe \n",
							"trainingFraction = 0.7\n",
							"testingFraction = (1-trainingFraction)\n",
							"seed = 1234\n",
							"\n",
							"# Split the dataframe into test and training dataframes\n",
							"train_data_df, test_data_df = encoded_final_df.randomSplit([trainingFraction, testingFraction], seed=seed)"
						],
						"outputs": [],
						"execution_count": 9
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Train the Model\n",
							"\n",
							"Train the Logistic Regression model and then evaluate it using Area under ROC as the metric."
						]
					},
					{
						"cell_type": "code",
						"source": [
							"## Create a new LR object for the model\n",
							"logReg = LogisticRegression(maxIter=10, regParam=0.3, labelCol = 'tipped')\n",
							"\n",
							"## The formula for the model\n",
							"classFormula = RFormula(formula=\"tipped ~ pickupHour + weekdayVec + passengerCount + tripTimeSecs + tripDistance + fareAmount + paymentType+ trafficTimeBinsVec\")\n",
							"\n",
							"## Undertake training and create an LR model\n",
							"lrModel = Pipeline(stages=[classFormula, logReg]).fit(train_data_df)\n",
							"\n",
							"## Saving the model is optional but its another for of inter session cache\n",
							"datestamp = datetime.now().strftime('%m-%d-%Y-%s');\n",
							"fileName = \"lrModel_\" + datestamp;\n",
							"logRegDirfilename = fileName;\n",
							"lrModel.save(logRegDirfilename)\n",
							"\n",
							"## Predict tip 1/0 (yes/no) on the test dataset, evaluation using AUROC\n",
							"predictions = lrModel.transform(test_data_df)\n",
							"predictionAndLabels = predictions.select(\"prediction\", \"label\").rdd\n",
							"metrics = BinaryClassificationMetrics(predictionAndLabels)\n",
							"print(\"Area under ROC = %s\" % metrics.areaUnderROC)"
						],
						"outputs": [],
						"execution_count": 10
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Evaluate and Visualize\n",
							"\n",
							"Plot the actual curve to develop a better understanding of the model.\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"## Plot the ROC curve, no need for pandas as this uses the modelSummary object\n",
							"modelSummary = lrModel.stages[-1].summary\n",
							"\n",
							"plt.plot([0, 1], [0, 1], 'r--')\n",
							"plt.plot(modelSummary.roc.select('FPR').collect(),\n",
							"         modelSummary.roc.select('TPR').collect())\n",
							"plt.xlabel('False Positive Rate')\n",
							"plt.ylabel('True Positive Rate')\n",
							"plt.show()"
						],
						"outputs": [],
						"execution_count": 11
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Index Matching Example')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "d2d53cc1-6239-484c-8fed-ea3660513f3d"
					}
				},
				"metadata": {
					"saveOutput": true,
					"synapse_widget": {
						"version": "0.1"
					},
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "python"
					},
					"language_info": {
						"name": "python"
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"listA = ['Mon','Tue', 'Wed', 'Thu', 'Fri']\r\n",
							"listB = ['Tue', 'Fri']\r\n",
							"# Given lists\r\n",
							"print(\"The given list:\\n \",listA)\r\n",
							"print(\"The list of values:\\n \",listB)\r\n",
							"# using indices\r\n",
							"res = [listA.index(i) for i in listB]\r\n",
							"# Result\r\n",
							"print(\"The Match indices list is : \",res)\r\n",
							""
						],
						"outputs": []
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Matplotlib Example')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "SynapseDemoSprk",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "7c6f8e42-b394-40be-b855-324e0f3d7146"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/499bc654-f84c-46c2-952c-b30be508f78c/resourceGroups/Synapse-Demo/providers/Microsoft.Synapse/workspaces/rayfelipesynapseworkspace/bigDataPools/SynapseDemoSprk",
						"name": "SynapseDemoSprk",
						"type": "Spark",
						"endpoint": "https://rayfelipesynapseworkspace.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/SynapseDemoSprk",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.2",
						"nodeCount": 10,
						"cores": 4,
						"memory": 28,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"import matplotlib.pyplot as plt\r\n",
							"\r\n",
							"x1 = [1, 3, 4, 5, 6, 7, 9]\r\n",
							"y1 = [4, 7, 2, 4, 7, 8, 3]\r\n",
							"\r\n",
							"x2 = [2, 4, 6, 8, 10]\r\n",
							"y2 = [5, 6, 2, 6, 2]\r\n",
							"\r\n",
							"plt.bar(x1, y1, label=\"Blue Bar\", color='b')\r\n",
							"plt.bar(x2, y2, label=\"Green Bar\", color='g')\r\n",
							"plt.plot()\r\n",
							"\r\n",
							"plt.xlabel(\"bar number\")\r\n",
							"plt.ylabel(\"bar height\")\r\n",
							"plt.title(\"Bar Chart Example\")\r\n",
							"plt.legend()\r\n",
							"plt.show()"
						],
						"outputs": [],
						"execution_count": 1
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Notebook 4')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "SynapseDemoSpk2",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "112g",
					"driverCores": 16,
					"executorMemory": "112g",
					"executorCores": 16,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "085ff0d3-48e0-41bf-9b86-bc40ca8afd15"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/499bc654-f84c-46c2-952c-b30be508f78c/resourceGroups/Synapse-Demo/providers/Microsoft.Synapse/workspaces/rayfelipesynapseworkspace/bigDataPools/SynapseDemoSpk2",
						"name": "SynapseDemoSpk2",
						"type": "Spark",
						"endpoint": "https://rayfelipesynapseworkspace.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/SynapseDemoSpk2",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.2",
						"nodeCount": 10,
						"cores": 16,
						"memory": 112,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "python"
							}
						},
						"source": [
							"%%pyspark\n",
							"spark.sql(\"DROP DATABASE IF EXISTS cannabis CASCADE\")"
						],
						"outputs": [],
						"execution_count": 4
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/a-Load Into Spark DF')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "DCC"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "SynapseDemoSpk2",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "112g",
					"driverCores": 16,
					"executorMemory": "112g",
					"executorCores": 16,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "1d73f486-033b-4f25-bd9e-f883ae635d64"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/499bc654-f84c-46c2-952c-b30be508f78c/resourceGroups/Synapse-Demo/providers/Microsoft.Synapse/workspaces/rayfelipesynapseworkspace/bigDataPools/SynapseDemoSpk2",
						"name": "SynapseDemoSpk2",
						"type": "Spark",
						"endpoint": "https://rayfelipesynapseworkspace.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/SynapseDemoSpk2",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.2",
						"nodeCount": 10,
						"cores": 16,
						"memory": 112,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "python"
							},
							"collapsed": false
						},
						"source": [
							"%%pyspark\r\n",
							"df = spark.read.load('abfss://dcc@datalakaeacctindemorg.dfs.core.windows.net/CannabisAccountSitesByQuarter.csv', format='csv'\r\n",
							"## If header exists uncomment line below\r\n",
							"##, header=True\r\n",
							")\r\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 1
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SynapseDemoSprk')]",
			"type": "Microsoft.Synapse/workspaces/bigDataPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"autoPause": {
					"enabled": true,
					"delayInMinutes": 15
				},
				"autoScale": {
					"enabled": true,
					"maxNodeCount": 6,
					"minNodeCount": 3
				},
				"nodeCount": 10,
				"nodeSize": "Small",
				"nodeSizeFamily": "MemoryOptimized",
				"sparkVersion": "3.2",
				"isComputeIsolationEnabled": false,
				"sessionLevelPackagesEnabled": false,
				"annotations": []
			},
			"dependsOn": [],
			"location": "westus"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SynapseDemoSpk2')]",
			"type": "Microsoft.Synapse/workspaces/bigDataPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"autoPause": {
					"enabled": true,
					"delayInMinutes": 15
				},
				"autoScale": {
					"enabled": true,
					"maxNodeCount": 10,
					"minNodeCount": 3
				},
				"nodeCount": 10,
				"nodeSize": "Large",
				"nodeSizeFamily": "MemoryOptimized",
				"sparkVersion": "3.2",
				"isComputeIsolationEnabled": false,
				"sessionLevelPackagesEnabled": false,
				"annotations": []
			},
			"dependsOn": [],
			"location": "westus"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SynapseDemoSpk3')]",
			"type": "Microsoft.Synapse/workspaces/bigDataPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"autoPause": {
					"enabled": true,
					"delayInMinutes": 15
				},
				"autoScale": {
					"enabled": true,
					"maxNodeCount": 15,
					"minNodeCount": 3
				},
				"nodeCount": 10,
				"nodeSize": "Medium",
				"nodeSizeFamily": "MemoryOptimized",
				"sparkVersion": "3.2",
				"isComputeIsolationEnabled": false,
				"sessionLevelPackagesEnabled": false,
				"annotations": []
			},
			"dependsOn": [],
			"location": "westus"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SQL Dedicated 1')]",
			"type": "Microsoft.Synapse/workspaces/sqlPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"collation": "SQL_Latin1_General_CP1_CI_AS",
				"maxSizeBytes": 263882790666240,
				"annotations": []
			},
			"dependsOn": [],
			"location": "westus"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/LocalSynapse_LinkedService')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureSqlDW",
				"typeProperties": {
					"connectionString": "[parameters('LocalSynapse_LinkedService_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		}
	]
}